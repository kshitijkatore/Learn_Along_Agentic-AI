{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a68b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1+cu128'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33241541",
   "metadata": {},
   "source": [
    "``` Scaler ```\n",
    "\n",
    "* A scalar is a single number and in tensor-speak it's a zero dimension tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.tensor(7)\n",
    "print(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b480aaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dimension of tensor\n",
    "scaler.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c5b374c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the python nuber within a tensor\n",
    "\n",
    "scaler.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e02ae5",
   "metadata": {},
   "source": [
    "``` Vector ```\n",
    "* A vector is a single dimension tensor but can contain many numbers.\n",
    "\n",
    "* As in, you could have a vector [3, 2] to describe [bedrooms, bathrooms] in your house. Or you could have [3, 2, 2] to describe [bedrooms, bathrooms, car_parks] in your house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44c82401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 7])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([7,7])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aae05641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number dimensions of vector\n",
    "\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d78a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of vector\n",
    "\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f43f49",
   "metadata": {},
   "source": [
    "```Matrix```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c660ff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8],\n",
      "        [ 9, 10]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "matrix = torch.tensor([[7,8],\n",
    "                       [9,10]])\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e466ad81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimensions of matrix\n",
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b8e822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db454bc4",
   "metadata": {},
   "source": [
    "` Tensor `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccabc555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "\n",
    "tensor = torch.tensor([[[1,2,3],\n",
    "                        [3,6,9],\n",
    "                        [2,4,5]]])\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71549f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check of dimensions fo tensor\n",
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1a652b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d5a25",
   "metadata": {},
   "source": [
    "`` Tensor for random number ``\n",
    "* we can do so using torch.rand() and passing in the size parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7afccdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2074, 0.3296, 0.8139, 0.1406],\n",
       "         [0.1822, 0.8397, 0.4117, 0.7577],\n",
       "         [0.3322, 0.8761, 0.6096, 0.0371]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor of size (3,4)\n",
    "random_tensor = torch.rand(size=(3,4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "396989ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.3356, 0.2760, 0.6136],\n",
       "          [0.0700, 0.0495, 0.6335],\n",
       "          [0.4093, 0.2000, 0.2419],\n",
       "          ...,\n",
       "          [0.0091, 0.8157, 0.2895],\n",
       "          [0.7750, 0.8377, 0.9238],\n",
       "          [0.6525, 0.7510, 0.1399]],\n",
       " \n",
       "         [[0.2552, 0.3733, 0.3908],\n",
       "          [0.3378, 0.9951, 0.8472],\n",
       "          [0.2311, 0.4794, 0.4550],\n",
       "          ...,\n",
       "          [0.4320, 0.9919, 0.3773],\n",
       "          [0.9693, 0.5625, 0.3304],\n",
       "          [0.3920, 0.4944, 0.1405]],\n",
       " \n",
       "         [[0.0689, 0.8634, 0.7975],\n",
       "          [0.9072, 0.6762, 0.7806],\n",
       "          [0.2377, 0.4706, 0.3713],\n",
       "          ...,\n",
       "          [0.9988, 0.6717, 0.5472],\n",
       "          [0.8357, 0.8913, 0.7459],\n",
       "          [0.1606, 0.4984, 0.6569]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.4534, 0.3300, 0.0846],\n",
       "          [0.4599, 0.0610, 0.0144],\n",
       "          [0.0447, 0.3141, 0.2479],\n",
       "          ...,\n",
       "          [0.6307, 0.5496, 0.1192],\n",
       "          [0.5898, 0.7375, 0.5554],\n",
       "          [0.5140, 0.1036, 0.5676]],\n",
       " \n",
       "         [[0.8284, 0.8633, 0.3158],\n",
       "          [0.9907, 0.7968, 0.0882],\n",
       "          [0.6991, 0.2497, 0.3939],\n",
       "          ...,\n",
       "          [0.2426, 0.6295, 0.2499],\n",
       "          [0.6212, 0.5048, 0.3054],\n",
       "          [0.4041, 0.0877, 0.7419]],\n",
       " \n",
       "         [[0.8711, 0.5398, 0.8155],\n",
       "          [0.2331, 0.8983, 0.1738],\n",
       "          [0.8988, 0.2545, 0.0901],\n",
       "          ...,\n",
       "          [0.6172, 0.8368, 0.2142],\n",
       "          [0.2997, 0.0670, 0.9005],\n",
       "          [0.8785, 0.2239, 0.5146]]]),\n",
       " 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a random tensor of size\n",
    "\n",
    "random_image_size_tensor = torch.rand(size=(224,224,3))\n",
    "random_image_size_tensor, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde3dceb",
   "metadata": {},
   "source": [
    "* Create a tensor full of zeros with torch.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19169ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of all zeros\n",
    "\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb79531",
   "metadata": {},
   "source": [
    "* Create a tensors of all ones except using torch.ones()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7db72a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c0d603",
   "metadata": {},
   "source": [
    "` Create a range and tensors like `\n",
    "\n",
    "* you can use torch.arange(start, end step) to do so.\n",
    "\n",
    "* start = start of range\n",
    "* end = end of range\n",
    "* step = how many steps in between each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4eb2af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54355/4138096473.py:3: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  zero_ten_deprecated = torch.range(0, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use torch.range(), torch.arange()\n",
    "\n",
    "zero_ten_deprecated = torch.range(0, 10)\n",
    "\n",
    "zero_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6bf1dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can also a tensor of zeros simila to another tensor\n",
    "\n",
    "ten_zeros = torch.zeros_like(input=zero_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1508f",
   "metadata": {},
   "source": [
    "` Tensors Datatypes `\n",
    "* Default datatype for tensor is float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e409b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],\n",
    "                               dtype=None,\n",
    "                               device=None,\n",
    "                               requires_grad=False)\n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51361aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0,6.0,9.0],\n",
    "                               dtype=torch.float16,\n",
    "                               device=torch.device('cuda:0'))\n",
    "\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a06e1d8",
   "metadata": {},
   "source": [
    "` Getting information from tensor `\n",
    "\n",
    "* Three of the most common attribute you'll want to find out about tensors\n",
    "\n",
    "* Shape - What shape is tensor ?\n",
    "* dtype - what datatype are the elements within the tensor stored in?\n",
    "* device - what device is the tensor stored on? (usually GPU or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acda0f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0989, 0.1061, 0.3377, 0.8555],\n",
      "        [0.7510, 0.3107, 0.6933, 0.8734],\n",
      "        [0.2923, 0.9658, 0.4550, 0.7385]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Devise tensor is stores on: cpu\n"
     ]
    }
   ],
   "source": [
    "some_tensor = torch.rand(3,4)\n",
    "\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Devise tensor is stores on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de065faa",
   "metadata": {},
   "source": [
    "` Manipulating tensors (tensor operation) `\n",
    "* Addition\n",
    "* Substraction\n",
    "* Multiplication\n",
    "* Divison\n",
    "* Matrix mu;tiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5983a8c9",
   "metadata": {},
   "source": [
    "* Basics Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97ca41f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of value and add a number on it\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fea2f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply it by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "572f0155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substract and reassing\n",
    "tensor = tensor -10\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6cfb611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add and reassign\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25525b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can also use torch function\n",
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71e20acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c22d7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "\n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"Equals:\", tensor * tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fea741",
   "metadata": {},
   "source": [
    "` Matrix Multiplication `\n",
    "\n",
    "* The inner dimensions must match:\n",
    "*  (3, 2) @ (3, 2) won't work\n",
    "*  (2, 3) @ (3, 2) will work\n",
    "*  (3, 2) @ (2, 3) will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6e2551b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and perform element-wise multiplication and matrix multiplication\n",
    "\n",
    "import torch\n",
    "tensor = torch.tensor([1,2,3,4])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0335e",
   "metadata": {},
   "source": [
    "` Operation`\t `Calculation`\t `Code`\n",
    "* Element-wise multiplication\t[1*1, 2*2, 3*3] = [1, 4, 9]\t`tensor * tensor`\n",
    "* Matrix multiplication\t`[1*1 + 2*2 + 3*3] = [14]`\t`tensor.matmul(tensor)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c796532d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  4,  9, 16])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise matrix multiplication\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b37c99cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7aa05e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can also user \"@\" for matrix multiplication\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89434568",
   "metadata": {},
   "source": [
    "Matrix multiplication by hand\n",
    "\n",
    "* The in-bulit torch.matmul() method is faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfe7b4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.66 ms, sys: 28 μs, total: 1.69 ms\n",
      "Wall time: 1.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(30)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "value =0\n",
    "\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd407beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 198 μs, sys: 0 ns, total: 198 μs\n",
      "Wall time: 121 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(30)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d4ad004",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      3\u001b[39m tensor_a = torch.tensor([[\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m],\n\u001b[32m      4\u001b[39m                          [\u001b[32m3\u001b[39m,\u001b[32m4\u001b[39m],\n\u001b[32m      5\u001b[39m                          [\u001b[32m5\u001b[39m,\u001b[32m6\u001b[39m]])\n\u001b[32m      7\u001b[39m tensor_b = torch.tensor([[\u001b[32m7\u001b[39m,\u001b[32m10\u001b[39m],\n\u001b[32m      8\u001b[39m                         [\u001b[32m8\u001b[39m,\u001b[32m11\u001b[39m],\n\u001b[32m      9\u001b[39m                         [\u001b[32m9\u001b[39m,\u001b[32m12\u001b[39m]])\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtensor_b\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shape need to be in the right way\n",
    "\n",
    "tensor_a = torch.tensor([[1,2],\n",
    "                         [3,4],\n",
    "                         [5,6]])\n",
    "\n",
    "tensor_b = torch.tensor([[7,10],\n",
    "                        [8,11],\n",
    "                        [9,12]])\n",
    "\n",
    "torch.matmul(tensor_a,tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa3e87",
   "metadata": {},
   "source": [
    "`Transpose`\n",
    "\n",
    "* torch.transpose(input, dim0, dim1) - where input is the desired tensor to transpose and dim0 and dim1 are the dimensions to be swapped.\n",
    "* tensor.T - where tensor is the desired tensor to transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78b40f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[ 7, 10],\n",
      "        [ 8, 11],\n",
      "        [ 9, 12]])\n"
     ]
    }
   ],
   "source": [
    "# view tensor_a and tensor_b\n",
    "print(tensor_a)\n",
    "print(tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad16aa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[ 7,  8,  9],\n",
      "        [10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# vies tensor_a and tensor_b.T\n",
    "\n",
    "print(tensor_a)\n",
    "print(tensor_b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fb696c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The operation works when tensor_b is transposed\n",
    "\n",
    "output = torch.matmul(tensor_a, tensor_b.T)\n",
    "\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55db6c8b",
   "metadata": {},
   "source": [
    "* You cal also use torch.mm() which is a short for torch.matmul()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2e96bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n"
     ]
    }
   ],
   "source": [
    "output = torch.mm(tensor_a, tensor_b.T)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c720b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Innput shape:  torch.Size([3, 2])\n",
      "Output shape torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Thise uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, out_features=6) # in_features = matches inner diension of input, out_featurs = describes outer value\n",
    "\n",
    "x =  tensor_a\n",
    "\n",
    "print(\"Innput shape: \", x.shape)\n",
    "print(\"Output shape\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59155a",
   "metadata": {},
   "source": [
    "Finding the min, max, mean, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87e88abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03fe23c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum : 0\n",
      "Maximum : 90\n",
      "Mean 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minimum : {x.min()}\")\n",
    "print(f\"Maximum : {x.max()}\")\n",
    "print(f\"Mean {x.type(torch.float32).mean()}\")\n",
    "print(f\"Sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d571c04",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# You can also do the same as above with torch meathod\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m torch.max(x), torch.min(x), \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, torch.mean(x.type(torch.float32)) , torch.sum()\n",
      "\u001b[31mRuntimeError\u001b[39m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "# You can also do the same as above with torch meathod\n",
    "\n",
    "torch.max(x), torch.min(x), torch.mean(x), torch.mean(x.type(torch.float32)) , torch.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d92fd0",
   "metadata": {},
   "source": [
    "` Positional min/max`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "372a2fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurce: 8\n",
      "Index where min value occurse: 0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(10, 100, 10)\n",
    "\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "print(f\"Index where max value occurce: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurse: {tensor.argmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3504d4e2",
   "metadata": {},
   "source": [
    "`Change tensor datatype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a8ccea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and check its datatype\n",
    "\n",
    "tensor = torch.arange(10., 100., 10.)\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45262a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a floate16 tensor\n",
    "\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18622ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an int8 tensor\n",
    "\n",
    "tensor_int8 = tensor.type(torch.int8)\n",
    "tensor_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ea437",
   "metadata": {},
   "source": [
    "` Reshaping, staking, squeezing and unsqueezing`\n",
    "\n",
    "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65eacb6",
   "metadata": {},
   "source": [
    "`Why do any of these`\n",
    "\n",
    "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e72eccf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "\n",
    "import torch\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac373383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's add an extra dimention with torch.reshape\n",
    "\n",
    "# add extra dimention\n",
    "\n",
    "x_reshaped = x.reshape(1,7)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db22c929",
   "metadata": {},
   "source": [
    "` Change th view with torch.view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f65ad8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change view (keeps same data as original but changes view)\n",
    "\n",
    "z = x.view(1,7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a206a5b",
   "metadata": {},
   "source": [
    "Rememder though. changing the view of a tensor with torch.view() really only creates a new view of the same tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4cf7a5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x\n",
    "\n",
    "z[:, 0] =5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec51d692",
   "metadata": {},
   "source": [
    "if we wanted to stack our new tensor on top of itself five times, we could do so with torch.stack()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ece7085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on the top of each other\n",
    "\n",
    "x_stacked = torch.stack([x,x,x,x], dim=0) # try changing dim to dim=1 and see what happens\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0cbac7",
   "metadata": {},
   "source": [
    "How about removing all single dimensions from a tensor ?\n",
    "\n",
    "to do so you can use torch.squeeze() (i remember this as squeezing the tensor to only have dimension over 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d590dfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "Previous shape: torch.Size([1, 7])\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "New shape: torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"New tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eb5327",
   "metadata": {},
   "source": [
    "And to do the reverse of  torch.squeeze() you can use torch.unsqueeze() to add a dimension value of 1 at a specific index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6818aa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "Previous shape: torch.Size([7])\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "New shape: torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"New tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aad3e8",
   "metadata": {},
   "source": [
    "you can also rearange the order of axes values with torch.permute(input, dims), where the input gets turned into a view with new dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bed77d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor with specific shape\n",
    "\n",
    "x_original = torch.rand(size=(224,224,3))\n",
    "\n",
    "#Premutes the original tensor to rearrange the axis order\n",
    "x_premute = x_original.permute(2,0,1)\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_premute.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94cc74b",
   "metadata": {},
   "source": [
    "`Indexing (Selecting data from tensors)`\n",
    "\n",
    "dometimes you'll want to select specific data from tensors (for example only the first column or second row)\n",
    "\n",
    "To do so, you can use indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fbff49a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a tensor\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.arange(1,10).reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2262a5",
   "metadata": {},
   "source": [
    "indexing values goes outer dimension -> inner dimension (check out the square brackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "abc3ac43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first square brackets:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square brackets: tensor([1, 2, 3])\n",
      "Third square brackets: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"first square brackets:\\n {x[0]}\")\n",
    "print(f\"Second square brackets: {x[0][0]}\")\n",
    "print(f\"Third square brackets: {x[0][0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977fcb88",
   "metadata": {},
   "source": [
    "You can also use : to specify all values in this dimension and then use a comma(,) to add another dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c7db240b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0]\n",
    "x[:,2] # third row\n",
    "x[:,:,1] # accesing second column\n",
    "x[:,:,0]  # accesing first column\n",
    "x[0,0,:] # get index 0 of oth and 1st dimension and all values of 2nd dimesion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5c400",
   "metadata": {},
   "source": [
    "`PyTorch tensors & Numpy`\n",
    "\n",
    "THe two main method you'll want to use for Numpy to Pytorch(and back again) are:\n",
    "\n",
    "* torch.from_numpy(ndarray) -Numpy array -> PyTorch tensor\n",
    "* torch.Tensor.numpy() -PyTorch tensor ->Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "796f5e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array to tensor\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0,8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1fe2ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the array keep the tensor\n",
    "\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435b28c",
   "metadata": {},
   "source": [
    "if you want to go from PyTorch tensor to NUmpy array, you can call tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6709399c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to Numpy array\n",
    "\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb750f",
   "metadata": {},
   "source": [
    "`Reproducibility (trying to take the random out of random)`\n",
    "\n",
    "Example of reproducibility in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a395faaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A: \n",
      " tensor([[0.8660, 0.2001, 0.7926, 0.1140],\n",
      "        [0.6855, 0.0086, 0.3588, 0.9211],\n",
      "        [0.8627, 0.8223, 0.5248, 0.5881]])\n",
      "Tensor B:\n",
      " tensor([[0.2746, 0.3791, 0.2975, 0.6450],\n",
      "        [0.0163, 0.9160, 0.5888, 0.8403],\n",
      "        [0.4761, 0.7140, 0.4644, 0.6362]])\n",
      "Does Tensor A equel Tensor B? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#Create two random tensors\n",
    "\n",
    "random_tensor_A = torch.rand(3,4)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "\n",
    "print(f\"Tensor A: \\n {random_tensor_A}\")\n",
    "print(f\"Tensor B:\\n {random_tensor_B}\")\n",
    "\n",
    "print(f\"Does Tensor A equel Tensor B? (anywhere)\")\n",
    "\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83a8c67",
   "metadata": {},
   "source": [
    "But what if you wanted to create two random tensors with the same values.\n",
    "\n",
    "As in, the tensors would still contain random values but they would be of the same flavour.\n",
    "\n",
    "That's where torch.manual_seed(seed) comes in, where seed is an integer (like 42 but it could be anything) that flavours the randomness.\n",
    "\n",
    "Let's try it out by creating some more flavoured random tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "08cb69e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      " tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "Tensor D:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "#Have to reset the seed every time a new rand() is called\n",
    "# without this, tensor_D would be different to tensor_c\n",
    "\n",
    "torch.random.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n {random_tensor_C}\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\")\n",
    "\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc69c36",
   "metadata": {},
   "source": [
    "`Running tensors on GPU (and making faster computation)`\n",
    "\n",
    "Deep learning algorithms require a lot of numerical operations.\n",
    "\n",
    "And by default these operations are often done on a CPU (computer processing unit).\n",
    "\n",
    "However, there's another common piece of hardware called a GPU (graphics processing unit), which is often much faster at performing the specific types of operations neural networks need (matrix multiplications) than CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c55ad8",
   "metadata": {},
   "source": [
    "` 1. Getting a GPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "24ddb939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan  9 19:19:22 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650        Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   41C    P8              2W /   50W |     120MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1086      G   /usr/lib/Xorg                             4MiB |\n",
      "|    0   N/A  N/A            1545    C+G   /usr/bin/swayosd-server                   4MiB |\n",
      "|    0   N/A  N/A            1622    C+G   /usr/bin/walker                          43MiB |\n",
      "|    0   N/A  N/A           54355      C   ...g_Agentic-AI/.venv/bin/python         62MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6be46c5",
   "metadata": {},
   "source": [
    "`2. Getting PyTorch to run on the GPU`\n",
    "Once you've got a GPU ready to access, the next step is getting PyTorch to use for storing data (tensors) and computing on data (performing operations on tensors).\n",
    "\n",
    "To do so, you can use the torch.cuda package.\n",
    "\n",
    "Rather than talk about it, let's try it out.\n",
    "\n",
    "You can test if PyTorch has access to a GPU using torch.cuda.is_available()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "de325c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e937ed98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set devise type\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "00234878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of devices\n",
    "\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c2cdc4",
   "metadata": {},
   "source": [
    "Let's tey creating a tensor and putting it on the GPU (if it's available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "76cecd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create tensor (default on CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tesnso not on GPU\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Move tensor to GPU (if available)\n",
    "tensor_on_GPU = tensor.to(device)\n",
    "tensor_on_GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44285739",
   "metadata": {},
   "source": [
    "`4. Moving tensors back to the CPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a96d3b49",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# If tensor is on GPU, cant transform it to Numpy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtensor_on_GPU\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, cant transform it to Numpy\n",
    "\n",
    "tensor_on_GPU.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c93c1d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thise copies the tensor to CPU memory so its usable with CPUs\n",
    "\n",
    "# Insted, copy the tensor back to cpu\n",
    "tensor_back_on_cpu = tensor_on_GPU.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "013c94f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above returns a copy of the GPU tensor in CPU memory so the original tensor is still on GPU\n",
    "\n",
    "tensor_on_GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02135bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
